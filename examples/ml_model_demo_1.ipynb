{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating a neural network to classify dust events "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'livelossplot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-d54422624519>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m )\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlivelossplot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPlotLossesKeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'livelossplot'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import rasterio\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import imgaug as ia\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from loss_plot import TrainingPlot\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from IPython.display import clear_output\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import (\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    ")\n",
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    "    Dense,\n",
    "    Conv2D,\n",
    "    UpSampling2D,\n",
    "    MaxPooling2D,\n",
    "    Dropout,\n",
    "    concatenate,\n",
    "    Conv2DTranspose,\n",
    "    BatchNormalization,\n",
    "    Flatten\n",
    ")\n",
    "\n",
    "ia.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting livelossplot\n",
      "  Downloading livelossplot-0.5.3-py3-none-any.whl (30 kB)\n",
      "Requirement already satisfied: ipython in /nas/rhome/mramasub/anaconda2/envs/ipykernel_py3/lib/python3.6/site-packages (from livelossplot) (7.16.1)\n",
      "Processing /nas/rhome/mramasub/.cache/pip/wheels/11/a1/ab/95c829a84c40527b5972d3861fc06253aaf12c7e738621d19c/bokeh-2.2.0-py3-none-any.whl\n",
      "Requirement already satisfied: matplotlib; python_version >= \"3.6\" in /nas/rhome/mramasub/anaconda2/envs/ipykernel_py3/lib/python3.6/site-packages (from livelossplot) (3.2.2)\n",
      "Requirement already satisfied: pygments in /nas/rhome/mramasub/anaconda2/envs/ipykernel_py3/lib/python3.6/site-packages (from ipython->livelossplot) (2.2.0)\n",
      "Requirement already satisfied: backcall in /nas/rhome/mramasub/anaconda2/envs/ipykernel_py3/lib/python3.6/site-packages (from ipython->livelossplot) (0.2.0)\n",
      "Requirement already satisfied: decorator in /nas/rhome/mramasub/anaconda2/envs/ipykernel_py3/lib/python3.6/site-packages (from ipython->livelossplot) (4.4.2)\n",
      "Requirement already satisfied: pickleshare in /nas/rhome/mramasub/anaconda2/envs/ipykernel_py3/lib/python3.6/site-packages (from ipython->livelossplot) (0.7.4)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /nas/rhome/mramasub/anaconda2/envs/ipykernel_py3/lib/python3.6/site-packages (from ipython->livelossplot) (4.2.1)\n",
      "Requirement already satisfied: jedi>=0.10 in /nas/rhome/mramasub/anaconda2/envs/ipykernel_py3/lib/python3.6/site-packages (from ipython->livelossplot) (0.10.2)\n",
      "Requirement already satisfied: setuptools>=18.5 in /nas/rhome/mramasub/anaconda2/envs/ipykernel_py3/lib/python3.6/site-packages (from ipython->livelossplot) (46.1.3)\n",
      "Requirement already satisfied: traitlets>=4.2 in /nas/rhome/mramasub/anaconda2/envs/ipykernel_py3/lib/python3.6/site-packages (from ipython->livelossplot) (4.3.2)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /nas/rhome/mramasub/anaconda2/envs/ipykernel_py3/lib/python3.6/site-packages (from ipython->livelossplot) (3.0.5)\n",
      "Requirement already satisfied: Jinja2>=2.7 in /nas/rhome/mramasub/anaconda2/envs/ipykernel_py3/lib/python3.6/site-packages (from bokeh; python_version >= \"3.6\"->livelossplot) (2.11.2)\n",
      "Collecting typing-extensions>=3.7.4\n",
      "  Using cached typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: pillow>=7.1.0 in /nas/rhome/mramasub/anaconda2/envs/ipykernel_py3/lib/python3.6/site-packages (from bokeh; python_version >= \"3.6\"->livelossplot) (7.2.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /nas/rhome/mramasub/anaconda2/envs/ipykernel_py3/lib/python3.6/site-packages (from bokeh; python_version >= \"3.6\"->livelossplot) (1.19.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /nas/rhome/mramasub/anaconda2/envs/ipykernel_py3/lib/python3.6/site-packages (from bokeh; python_version >= \"3.6\"->livelossplot) (2.8.1)\n",
      "Requirement already satisfied: packaging>=16.8 in /nas/rhome/mramasub/anaconda2/envs/ipykernel_py3/lib/python3.6/site-packages (from bokeh; python_version >= \"3.6\"->livelossplot) (20.4)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /nas/rhome/mramasub/anaconda2/envs/ipykernel_py3/lib/python3.6/site-packages (from bokeh; python_version >= \"3.6\"->livelossplot) (5.3.1)\n",
      "Processing /nas/rhome/mramasub/.cache/pip/wheels/93/84/2f/409c7b2bb3afc3aa727f7ee8787975e0793f74d1165f4d0104/tornado-6.0.4-cp36-cp36m-linux_x86_64.whl\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /nas/rhome/mramasub/anaconda2/envs/ipykernel_py3/lib/python3.6/site-packages (from matplotlib; python_version >= \"3.6\"->livelossplot) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /nas/rhome/mramasub/anaconda2/envs/ipykernel_py3/lib/python3.6/site-packages (from matplotlib; python_version >= \"3.6\"->livelossplot) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /nas/rhome/mramasub/anaconda2/envs/ipykernel_py3/lib/python3.6/site-packages (from matplotlib; python_version >= \"3.6\"->livelossplot) (1.2.0)\n",
      "Requirement already satisfied: wcwidth in /nas/rhome/mramasub/anaconda2/envs/ipykernel_py3/lib/python3.6/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->livelossplot) (0.1.7)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /nas/rhome/mramasub/anaconda2/envs/ipykernel_py3/lib/python3.6/site-packages (from Jinja2>=2.7->bokeh; python_version >= \"3.6\"->livelossplot) (1.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /nas/rhome/mramasub/anaconda2/envs/ipykernel_py3/lib/python3.6/site-packages (from python-dateutil>=2.1->bokeh; python_version >= \"3.6\"->livelossplot) (1.15.0)\n",
      "Installing collected packages: typing-extensions, tornado, bokeh, livelossplot\n",
      "  Attempting uninstall: tornado\n",
      "    Found existing installation: tornado 4.5.2\n",
      "\u001b[31mERROR: Cannot uninstall 'tornado'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install livelossplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration variables\n",
    "input_size = 256\n",
    "n_channels = 3\n",
    "model_save_path = 'test_model.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating dataset generator and augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnetGenerator(tf.keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "\n",
    "    def __init__(self, data_path,\n",
    "                 to_fit=True, batch_size=1, dim=(256, 256),\n",
    "                 n_channels=3, shuffle=True, augment=True):\n",
    "        'Initialization'\n",
    "        self.data_path = data_path\n",
    "        self.tif_list = []\n",
    "        self.mask_list = []\n",
    "        for filename in glob(f'{data_path}*.tif*'):\n",
    "            self.tif_list.append(filename)\n",
    "\n",
    "        self.to_fit = to_fit\n",
    "        self.augment = augment\n",
    "        self.batch_size = batch_size\n",
    "        self.dim = dim\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.n = 0\n",
    "        self.max = self.__len__()\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.tif_list) / self.batch_size))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.tif_list))\n",
    "        if self.shuffle is True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index *\n",
    "                               self.batch_size: (index + 1) * self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        tif_list_temp = [self.tif_list[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X = self._generate_X(tif_list_temp)\n",
    "\n",
    "        #  preprocess and augment data\n",
    "\n",
    "        if self.to_fit:\n",
    "            y = self._generate_y(tif_list_temp)\n",
    "\n",
    "            if self.augment:\n",
    "                seq = make_augmentations()\n",
    "                images_aug = list()\n",
    "                labels_aug = list()\n",
    "                for i in range(len(X)):\n",
    "                    image, label = seq(\n",
    "                        image=X[i].astype('float32'),\n",
    "                        segmentation_maps=np.expand_dims(\n",
    "                            y[i], 0).astype('uint8')\n",
    "                    )\n",
    "                    images_aug.append(image)\n",
    "                    labels_aug.append(label[0, :, :, :])\n",
    "\n",
    "                return np.array(images_aug), np.array(labels_aug)\n",
    "            else:\n",
    "                # import ipdb; ipdb.set_trace()\n",
    "                return X, y[:,:,:,0]\n",
    "\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "    def _generate_X(self, tif_list_temp):\n",
    "        'Generates data containing batch_size images'\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(tif_list_temp):\n",
    "            # Store sample\n",
    "            X[i, ] = _load_tif_image(ID, self.dim)\n",
    "\n",
    "        return X\n",
    "\n",
    "    def _generate_y(self, tif_list_temp):\n",
    "        'Generates data containing batch_size masks'\n",
    "        y = np.empty((self.batch_size, *self.dim, 1), dtype='float32')\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(tif_list_temp):\n",
    "            # Store sample\n",
    "            y[i, ] = _load_grayscale_image(ID.replace(\n",
    "                '.tiff', '_bitmap.png'), self.dim\n",
    "            )\n",
    "\n",
    "        return y\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.n >= self.max:\n",
    "            self.n = 0\n",
    "        result = self.__getitem__(self.n)\n",
    "        self.n += 1\n",
    "        return result\n",
    "\n",
    "\n",
    "def _load_grayscale_image(image_path, dim):\n",
    "    'Load grayscale image'\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = img / 255\n",
    "\n",
    "    return np.expand_dims(cv2.resize(img, dim), -1)\n",
    "\n",
    "\n",
    "def _load_tif_image(image_path, dim):\n",
    "    'load tif image'\n",
    "\n",
    "    with rasterio.open(image_path, 'r') as data:\n",
    "        return cv2.resize(\n",
    "            np.moveaxis(data.read(), 0, -1), dim\n",
    "        )\n",
    "\n",
    "\n",
    "def sometimes(aug):\n",
    "    return iaa.Sometimes(0.5, aug)\n",
    "\n",
    "def make_augmentations():\n",
    "\n",
    "    return iaa.Sequential([\n",
    "        sometimes(iaa.CoarseDropout(0.1, size_percent=0.2)),\n",
    "        sometimes(\n",
    "            iaa.Affine(\n",
    "                scale={\"x\": (0.9, 1.1), \"y\": (0.9, 1.1)},\n",
    "                # scale images to 80-120% of their size,\n",
    "                # individually per axis\n",
    "                translate_percent={\n",
    "                    \"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)},\n",
    "                # translate by -20 to +20 percent (per axis)\n",
    "                # rotate by -45 to +45 degrees\n",
    "                rotate=(-10, 10),\n",
    "                shear=(-5, 5),  # shear by -16 to +16 degrees\n",
    "            ),\n",
    "        ),\n",
    "        sometimes(iaa.ElasticTransformation(alpha=10, sigma=1))\n",
    "    ],\n",
    "        random_order=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 256, 256, 24) 672         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 256, 256, 24) 96          conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 256, 256, 24) 5208        batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 256, 256, 24) 96          conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 256, 256, 24) 5208        batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 128, 128, 24) 0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 128, 128, 24) 96          max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 128, 128, 24) 5208        batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 128, 128, 24) 96          conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 128, 128, 24) 5208        batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 128, 128, 24) 96          conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 128, 128, 24) 5208        batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 64, 64, 24)   0           conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 64, 64, 24)   96          max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 64, 64, 24)   5208        batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 64, 64, 24)   96          conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 64, 64, 24)   5208        batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 64, 64, 24)   96          conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 64, 64, 24)   5208        batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 32, 32, 24)   0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 32, 32, 24)   96          max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 32, 32, 24)   5208        batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 32, 32, 24)   96          conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 32, 32, 24)   5208        batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 32, 32, 24)   96          conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 64, 64, 24)   5208        batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 64, 64, 48)   0           conv2d_transpose_3[0][0]         \n",
      "                                                                 conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 64, 64, 48)   192         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 64, 64, 32)   13856       batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 64, 64, 32)   128         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 64, 64, 24)   6936        batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 64, 64, 24)   96          conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 128, 128, 24) 5208        batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 128, 128, 48) 0           conv2d_transpose_4[0][0]         \n",
      "                                                                 conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 128, 128, 48) 192         concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 128, 128, 32) 13856       batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 128, 128, 32) 128         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 128, 128, 24) 6936        batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 128, 128, 24) 96          conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTrans (None, 256, 256, 24) 5208        batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 256, 256, 48) 0           conv2d_transpose_5[0][0]         \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 256, 256, 48) 192         concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 256, 256, 32) 13856       batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 256, 256, 32) 128         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 256, 256, 24) 6936        batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 256, 256, 1)  25          conv2d_35[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 132,985\n",
      "Trainable params: 131,881\n",
      "Non-trainable params: 1,104\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_layers = 2\n",
    "input_shape = (input_size, input_size, 3)\n",
    "inputs = Input(input_shape)\n",
    "\n",
    "def bn_conv_relu(input, filters, bachnorm_momentum, **conv2d_args):\n",
    "    x = BatchNormalization(momentum=bachnorm_momentum)(input)\n",
    "    x = Conv2D(filters, **conv2d_args)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def bn_upconv_relu(input, filters, bachnorm_momentum, **conv2d_trans_args):\n",
    "    x = BatchNormalization(momentum=bachnorm_momentum)(input)\n",
    "    x = Conv2DTranspose(filters, **conv2d_trans_args)(x)\n",
    "    return x\n",
    "\n",
    "filters = 24\n",
    "upconv_filters = 32\n",
    "\n",
    "kernel_size = (3, 3)\n",
    "activation = 'relu'\n",
    "strides = (1, 1)\n",
    "padding = 'same'\n",
    "kernel_initializer = 'he_normal'\n",
    "output_activation = 'sigmoid'\n",
    "\n",
    "conv2d_args = {\n",
    "    'kernel_size': kernel_size,\n",
    "    'activation': activation,\n",
    "    'strides': strides,\n",
    "    'padding': padding,\n",
    "    'kernel_initializer': kernel_initializer\n",
    "}\n",
    "\n",
    "conv2d_trans_args = {\n",
    "    'kernel_size': kernel_size,\n",
    "    'activation': activation,\n",
    "    'strides': (2, 2),\n",
    "    'padding': padding,\n",
    "}\n",
    "\n",
    "bachnorm_momentum = 0.01\n",
    "\n",
    "pool_size = (2, 2)\n",
    "pool_strides = (2, 2)\n",
    "pool_padding = 'valid'\n",
    "\n",
    "maxpool2d_args = {\n",
    "    'pool_size': pool_size,\n",
    "    'strides': pool_strides,\n",
    "    'padding': pool_padding,\n",
    "}\n",
    "\n",
    "x = Conv2D(filters, **conv2d_args)(inputs)\n",
    "c1 = bn_conv_relu(x, filters, bachnorm_momentum, **conv2d_args)\n",
    "x = bn_conv_relu(c1, filters, bachnorm_momentum, **conv2d_args)\n",
    "x = MaxPooling2D(**maxpool2d_args)(x)\n",
    "\n",
    "down_layers = []\n",
    "\n",
    "for l in range(num_layers):\n",
    "    x = bn_conv_relu(x, filters, bachnorm_momentum, **conv2d_args)\n",
    "    x = bn_conv_relu(x, filters, bachnorm_momentum, **conv2d_args)\n",
    "    down_layers.append(x)\n",
    "    x = bn_conv_relu(x, filters, bachnorm_momentum, **conv2d_args)\n",
    "    x = MaxPooling2D(**maxpool2d_args)(x)\n",
    "\n",
    "x = bn_conv_relu(x, filters, bachnorm_momentum, **conv2d_args)\n",
    "x = bn_conv_relu(x, filters, bachnorm_momentum, **conv2d_args)\n",
    "x = bn_upconv_relu(x, filters, bachnorm_momentum, **conv2d_trans_args)\n",
    "\n",
    "for conv in reversed(down_layers):\n",
    "    x = concatenate([x, conv])\n",
    "    x = bn_conv_relu(\n",
    "        x, upconv_filters, bachnorm_momentum, **conv2d_args\n",
    "    )\n",
    "    x = bn_conv_relu(x, filters, bachnorm_momentum, **conv2d_args)\n",
    "    x = bn_upconv_relu(\n",
    "        x, filters, bachnorm_momentum, **conv2d_trans_args\n",
    "    )\n",
    "\n",
    "x = concatenate([x, c1])\n",
    "x = bn_conv_relu(x, upconv_filters, bachnorm_momentum, **conv2d_args)\n",
    "x = bn_conv_relu(x, filters, bachnorm_momentum, **conv2d_args)\n",
    "\n",
    "outputs = Conv2D(\n",
    "    1,\n",
    "    kernel_size=(1, 1),\n",
    "    strides=(1, 1),\n",
    "    activation=output_activation,\n",
    "    padding='valid')(x)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[outputs])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlotLearning(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.acc = []\n",
    "        self.val_acc = []\n",
    "        self.fig = plt.figure()\n",
    "        \n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        self.logs.append(logs)\n",
    "        self.x.append(self.i)\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.acc.append(logs.get('acc'))\n",
    "        self.val_acc.append(logs.get('val_acc'))\n",
    "        self.i += 1\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        ax1.set_yscale('log')\n",
    "        ax1.plot(self.x, self.losses, label=\"loss\")\n",
    "        ax1.plot(self.x, self.val_losses, label=\"val_loss\")\n",
    "        ax1.legend()\n",
    "        \n",
    "        ax2.plot(self.x, self.acc, label=\"accuracy\")\n",
    "        ax2.plot(self.x, self.val_acc, label=\"validation accuracy\")\n",
    "        ax2.legend()\n",
    "        \n",
    "        plt.show();\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=20,\n",
    "                  verbose=1, mode=\"auto\"),\n",
    "    ModelCheckpoint(filepath=model_save_path,\n",
    "                    verbose=1, save_best_only=True),\n",
    "    PlotLearning(),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compiling the model with appropriate optimizer, loss and metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(\n",
    "                learning_rate=0.00001,\n",
    "                beta_1=0.9,\n",
    "                beta_2=0.999,\n",
    "                epsilon=1e-07,\n",
    "                amsgrad=False,\n",
    "            ),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### downloading  the dataset and using the created generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = UnetGenerator('../../pixel-level-HLD-classifier/data/train/', batch_size=10)\n",
    "val_generator = UnetGenerator('../../pixel-level-HLD-classifier/data/val/', batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training the model with the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "24/25 [===========================>..] - ETA: 7s - loss: 0.8023 - accuracy: 0.5342 \n",
      "Epoch 00001: val_loss improved from inf to 0.75858, saving model to test_model.h5\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'clear_output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-d95b9609e7b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;32m~/anaconda2/envs/ipykernel_py3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1297\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/anaconda2/envs/ipykernel_py3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m       \u001b[0;31m# Epochs only apply to `fit`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m     \u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/ipykernel_py3/lib/python3.6/site-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m       \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-730367e6d3c6>\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0max1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_yscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clear_output' is not defined"
     ]
    }
   ],
   "source": [
    "results = model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs=200,\n",
    "    steps_per_epoch=25,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=callbacks,\n",
    "    validation_steps=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualizing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 3, constrained_layout=True, dpi=100)\n",
    "val_generator = UnetGenerator('../../pixel-level-HLD-classifier/data/val/',\n",
    "    batch_size=1,\n",
    "    augment=True\n",
    ")\n",
    "for i, batch_data in enumerate(val_generator):\n",
    "    if i == 101:\n",
    "        break\n",
    "    (modis_batch, bmp_batch) = batch_data\n",
    "    bmp_predict_batch = model.predict(modis_batch)\n",
    "    for j in range(len(modis_batch)):\n",
    "            ax[0].imshow(modis_batch[j].astype('uint8'))\n",
    "            ax[0].set_title('RGB Image')\n",
    "            ax[0].xaxis.set_ticks([])\n",
    "            ax[0].yaxis.set_ticks([])\n",
    "            ax[1].imshow(modis_batch[j].astype('uint8'))\n",
    "            ax[1].xaxis.set_ticks([])\n",
    "            ax[1].yaxis.set_ticks([])\n",
    "            ax[1].set_title('SME label overlay')\n",
    "            ax[2].imshow(modis_batch[j].astype('uint8'))\n",
    "            ax[2].set_title('Model Prediction overlay')\n",
    "            ax[2].xaxis.set_ticks([])\n",
    "            ax[2].yaxis.set_ticks([])\n",
    "            bmp_data = bmp_batch[j].astype('uint8')\n",
    "            ax[1].imshow(ma.masked_where(bmp_data != 1, bmp_data)[:,:,0],alpha=0.35,cmap='Purples')\n",
    "            ax[2].imshow(ma.masked_where(bmp_predict_batch[j] < 0.5, bmp_predict_batch2[j])[:,:,0],alpha=0.45,cmap='spring')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python ()",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
